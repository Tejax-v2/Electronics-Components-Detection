{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqZZsVCzvwhi"
      },
      "source": [
        "# Electronics components Detection using YOLOv11\n",
        "\n",
        "## Introduction\n",
        "\n",
        "This notebook will guide you through using YOLOv11 (You Only Look Once) Algorithm to detect electronics components such as capacitors, sensors, motor drivers, etc by training the YOLO model on a custom dataset ElectroCom61 which contains over 61 different classes for electronic components.\n",
        "\n",
        "## Credits\n",
        "\n",
        "- Dataset: [ElectroCom61](https://data.mendeley.com/datasets/6scy6h8sjz/1)\n",
        "- Reference: [Roboflow](https://github.com/roboflow/notebooks/blob/main/notebooks/train-yolov8-object-detection-on-custom-dataset.ipynb)\n",
        "- Model: [Ultralytics](https://github.com/ultralytics/ultralytics)\n",
        "\n",
        "## Table of Contents\n",
        "\n",
        "- [Introduction](#introduction)\n",
        "- [Prerequisites](#prerequisites)\n",
        "- [Installing YOLOv11](#installing-yolov11)\n",
        "- [Getting the Dataset](#getting-the-dataset)\n",
        "- [Sample Inference](#sample-inference)\n",
        "- [Training](#training)\n",
        "- [Validation](#validation) \n",
        "- [Performance](#performance)  \n",
        "- [Usage](#usage)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7AhC7EP0NYB"
      },
      "source": [
        "## Prerequisites\n",
        "\n",
        "We'll be using following tools for this notebook\n",
        "- Ultralytics YOLOv11 Model\n",
        "- ElectroCom61 Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiXH-kUM0YqE"
      },
      "source": [
        "Make sure you have access to GPU for faster computation. Run `nvidia-smi` command and check if you get output something like following"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-uPs_CF1QKI",
        "outputId": "eb8428a5-036d-479a-938c-64fb0c44e5fb"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwelRBfz1quc"
      },
      "source": [
        "You should get output something like above"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ei_2ISLc2A0K"
      },
      "source": [
        "Check Current Working Directory Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqsZXA5G2E6e",
        "outputId": "0b350c1e-4714-4cf1-80d2-d7e033152d42"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(HOME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCkkM_-p2LGa"
      },
      "source": [
        "## Installing YOLOv11\n",
        "\n",
        "Ultralytics package includes all necessary libraries and dependencies used to run YOLOv11. So installation is quite simple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIeeOmj82eKQ",
        "outputId": "90c77449-03d3-44c7-bb43-80dce76e720c"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-LOeiop2mqk"
      },
      "source": [
        "Make sure that ultralytics is installed correctly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0XNLmPh2vnj",
        "outputId": "e6bb4c03-efee-49ef-dba9-c027ae362f4a"
      },
      "outputs": [],
      "source": [
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHC2mNNa2w8j"
      },
      "source": [
        "## Getting the Dataset\n",
        "\n",
        "We'll be using ElectroCom61 Dataset for our notebook. The dataset is downloaded from [here](https://data.mendeley.com/datasets/6scy6h8sjz/1)\n",
        "\n",
        "- Name: ElectroCom61\n",
        "- Format: YOLOv8\n",
        "- Images count: 2071\n",
        "- Image size: 640x640\n",
        "- Classes count: 61\n",
        "- Train/Val/Test Distribution: 70%:20%:10%\n",
        "\n",
        "Download the dataset from given link inside your current working directory and rename the folder to 'Electronics'\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FogsonWZ7jIW"
      },
      "source": [
        "## Sample Inference\n",
        "\n",
        "Now we're all set to run YOLO model. Let's test our installation on a sample image. We'll use a YOLO model pretrained on COCO dataset for inferencing\n",
        "\n",
        "**NOTE:** There are two ways to use YOLO models\n",
        "- Using CLI commands\n",
        "- Using Python code\n",
        "\n",
        "For more extensibility, we'll be using YOLO model with Python. Read more about CLI method in [Ultralytics YOLO Docs](https://docs.ultralytics.com/usage/cli/)\n",
        "\n",
        "I'll be using a sample image from Pinterest. You can use any image for this.\n",
        "\n",
        "**NOTE:** The image used here should contain atleast one entity from COCO classes. Refer [COCO](https://cocodataset.org/) dataset for checking available classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DKzpfsAI-EF1"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "from PIL import Image\n",
        "import supervision as sv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRN3QEzJScc9"
      },
      "source": [
        "Let's first see the original image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "ElLQ2McvRs-d",
        "outputId": "99702f1f-445d-4393-f4fe-588020122d8f"
      },
      "outputs": [],
      "source": [
        "sample = Image.open(f'sample.jpg')\n",
        "sv.plot_image(sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhXnDpa6Snpn"
      },
      "source": [
        "Now let's try running pretrained YOLO model on this image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEtPPg7C-Mlv",
        "outputId": "36eb98ff-83af-4fcd-9b18-ce8c554c3790"
      },
      "outputs": [],
      "source": [
        "model = YOLO('yolo11n.pt')\n",
        "results = model.predict(source=f'sample.jpg', conf=0.25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHFSPGGzTKRp"
      },
      "source": [
        "Let's plot the detection result what the model found out."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "Nvlm1Y54MgIX",
        "outputId": "e915798e-168e-4d26-8cfa-f3ec797264b0"
      },
      "outputs": [],
      "source": [
        "sv.plot_image(results[0].plot())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnIbYmPNTYCm"
      },
      "source": [
        "Seems like our model has got superpower to see the non-existent things. Let's increase the confidence threshold in parameters to avoid such invalid detections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T97qR1LhMR9x",
        "outputId": "1967e20c-b8e7-4c6a-a316-b755c3124ae0"
      },
      "outputs": [],
      "source": [
        "new_results = model.predict(source=f'sample.jpg', conf=0.8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "jKVsIG_KUDH0",
        "outputId": "da8c6831-4ce0-4d9c-ca99-d1bf41ea2b7d"
      },
      "outputs": [],
      "source": [
        "sv.plot_image(new_results[0].plot())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qf2FixQfUKhA"
      },
      "source": [
        "There you go!❤️\n",
        "\n",
        "For each detected object, you can find box coordinates, confidence score and class id using following code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hmr88PTxUIaq",
        "outputId": "dd3e1079-0f8f-4580-f551-4bc5982c7bfe"
      },
      "outputs": [],
      "source": [
        "print(f\"Box-Coordinates: {new_results[0].boxes.xyxy}\")\n",
        "print(f\"Confidence Scores: {new_results[0].boxes.conf}\")\n",
        "print(f\"Class IDs: {new_results[0].boxes.cls}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxmhLpuV2IcK"
      },
      "source": [
        "## Training\n",
        "\n",
        "Let's now train our model on the custom dataset. Pass the following hyperparameters in the train function\n",
        "- epochs: Number of epochs\n",
        "- lr0: Initial learning rate\n",
        "- lrf: Final learning rate\n",
        "- imgsz: Square input image size\n",
        "- batch: Input Batch size\n",
        "- save: To save the learned weights at checkpoints\n",
        "- device: To select computation device(CPU/GPU)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_37fF6uWgXY",
        "outputId": "d1ac422a-6db9-4713-be52-eb694c41f0a1"
      },
      "outputs": [],
      "source": [
        "results = model.train(data=f'Electronics/ElectroCom61/data.yaml', epochs=20, lr0=0.01, lrf=0.01, imgsz=640, batch=8, device=0, optimizer='AdamW')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqHs4156133C"
      },
      "source": [
        "After some trial-and-error, I found the nearly optimal set of hyperparameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KU7xhJ7H2Cb9"
      },
      "source": [
        "## Validation\n",
        "\n",
        "Now that our model is trained, let's check how well does it perform.\n",
        "mAP is a good indicator to measure model performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "57wzZ6Xai2sN"
      },
      "outputs": [],
      "source": [
        "# Load a model\n",
        "model = YOLO(\"runs/detect/train3/weights/best.pt\")  # load a custom model\n",
        "\n",
        "# Validate the model\n",
        "metrics = model.val()  \n",
        "metrics.box.map  # map50-95\n",
        "metrics.box.map50  # map50\n",
        "metrics.box.map75  # map75\n",
        "metrics.box.maps  # a list contains map50-95 of each category"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Performance\n",
        "\n",
        "YOLO provides a detailed visualisation of the model performance. Check out `runs/detect/train` folder for training performance, and `runs/detect/val` folder for validation performance.\n",
        "\n",
        "We achieved a mAP of 0.899 which is sufficiently reliable for any object detection task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Usage\n",
        "\n",
        "YOLO weights are now upgraded to detect Dataset classes. Now you can use the trained weights for detecting Electronic components.\n",
        "\n",
        "The trained weights are stored in `runs/detect/train/weights/best.pt` file. To use the trained weights on you images, first load the weights in a YOLO model. Then, use the model to detect objects in your images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = YOLO('runs/detect/train3/weights/best.pt')\n",
        "\n",
        "result = model.predict(source='Electronics/ElectroCom61/test/images/IMG_5229_JPG.rf.716e8ad846e9bc2c9a2fc21266bf280e.jpg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I have used an image from test images for testing the trained weights. Lets check how well our model performs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sv.plot_image(result[0].plot())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Portable Weights\n",
        "\n",
        "Now you can use you trained model any any machine with ultralytics installed. Just copy the weights `runs/detect/train/weights/best.pt` to your machine and load the YOLO model with those weights.\n",
        "\n",
        "Your model is now ready to _look_ at the images"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
